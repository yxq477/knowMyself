这算是一个个人兴趣的实验吧，运用到了极其稀少的NLP知识

# 想说明一下实验结果的不足：
1）我前次投稿的表述不清楚，并没有秀优越感的意思，由于误会产生了一些“脏数据”。我真的认识到知识不是用来炫耀的，我只是运气好，拥有了一个能理解更多知识的大脑而已。（罗翔老师教诲的大意）

2）数据处理方式很可能导致结果不同。我选择了分词词性判断，然后直接粗暴统计名词、形容词、（副形词？名形词？）词频。如果有人评价的是“不在意身高”，结果更加加重了“身高”一词的权重。我比较了几种关键词提取方法，觉得都不太适用这种短回答的关键词统计。原谅我只有大半天的NPL知识，如果有NPL处理经验的前辈愿意教授改进方法，鄙人不胜欢喜。

3）微博返回数据不一致，我试过10次以上，最多返回的数据也不到800条，但显示微博评论是有800+

4）还有就说统计偏差：一个是留下评论的人样本不足（不一定是女生），跟点赞数据比起来还是少很多（20%不到）。还有一个是统计对象抽样偏差，部分性格不那么愿意留言或者说已经脱单的只想静静观望的人，没有留下评论。


# 步骤：
1. 获取该页下的所有评论
2. 剥离回复昵称，只留下回复
3. 调取百度API 处理词性（文本需要分割）
4. 分类词性，留下名词和形容词副词（还有副形词和名形词？）
5. 查看画统计图的需要的数据形式 (https://www.wordclouds.com/ 直接传入重复词组）
6. count 词频
7. 画出统计图
8. 写文投稿吴彦虐

# 文件说明
data.html 是最原始的网页
final.html 是去掉 script 和 img 的网页
data_handler.js 是处理得到 data.js 的一些方法
data.js 是获取的初始数据
cout.png 是前一部分数量统计
result.txt 是经过词性过滤后的词组（取了名词，形容词，副形词，名形词）
wordclouds.png 是最终生成的词云